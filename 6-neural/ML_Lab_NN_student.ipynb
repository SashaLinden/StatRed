{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tqyOyy4Jam58"
   },
   "source": [
    "# ML LabExericise --- Neural Networks\n",
    "This notebook exercise has been developed by Simon Pauw and Rein van den Boomgaard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701602578886,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "xAAM4MvRam5-"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.datasets import load_digits\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6UFFEhKXam6B"
   },
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QN5WjV19am6C"
   },
   "source": [
    "In this notebook, you are going to implement a feedforward neural network with an arbitrary number of layers (be gentle on your laptop...), and with an arbitrary number of nodes in each layer. We will use the modern way of deriving the equations but the classical way of implementation... (i.e. we are not going to use a machine learning framework like Tensorflow or PyTorch)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hM8lcJbWam6D"
   },
   "source": [
    "## Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HgWgYXhqam6E"
   },
   "source": [
    "First, implement the activation function ``sigm`` and its derivative ``sigm_prime``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1701602591258,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "mWdKE8muam6G",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a940b7a511be5cfa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def sigm(v):\n",
    "    # return the sigmoid function value\n",
    "    #. Your solution here ...\n",
    "\n",
    "def sigm_prime(v):\n",
    "    # return the derivative of the sigmoid function\n",
    "    #. Your solution here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 1003,
     "status": "ok",
     "timestamp": 1701602596082,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "G5zSgC_0am6H",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-06e66783f7a26130",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "d1b32639-5388-4cb0-8e02-6b0c353cd915"
   },
   "outputs": [],
   "source": [
    "# plot functions\n",
    "x = np.arange(-5,5,0.1)\n",
    "plt.plot(x, sigm(x))\n",
    "plt.plot(x, sigm_prime(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LcPwO0Uuam6K"
   },
   "source": [
    "The `NN` class here below is not yet fully implemented. Your goal is to write all missing code. **Follow the steps outlined below the class.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 238,
     "status": "ok",
     "timestamp": 1701602601573,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "6hhGFbQaam6L",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-bb30d0ef04760baa",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "class NN(object):\n",
    "    def __init__(self, file=None, layerSizes=[2,2,1],\n",
    "                 activation_functions=(sigm, sigm_prime),\n",
    "                 seed=None):\n",
    "        if file is not None:\n",
    "            self.loadNetwork(file)\n",
    "        else:\n",
    "            self.layerSizes = layerSizes\n",
    "            self.numberOfLayers = len(layerSizes)\n",
    "            self.W = []\n",
    "            self.b = []\n",
    "            if seed is not None:\n",
    "                rng = np.random.default_rng(seed=seed)\n",
    "            else:\n",
    "                rng = np.random.default_rng()\n",
    "\n",
    "            for s_in, s_out in zip(layerSizes[:-1], layerSizes[1:]):\n",
    "                if seed == 0:\n",
    "                    W = np.zeros((s_out, s_in))\n",
    "                    b = np.zeros(s_out)\n",
    "                else:\n",
    "                    sigma = 2 * np.sqrt(6/(s_in+s_out))\n",
    "                    W = sigma * rng.normal(size=(s_out, s_in))\n",
    "                    b = sigma * rng.normal(size=s_out)\n",
    "\n",
    "                self.W.append(W)\n",
    "                self.b.append(b)\n",
    "\n",
    "        self.g, self.g_prime = activation_functions\n",
    "\n",
    "    def getLayerSizes(self):\n",
    "        \"\"\"get the sizes of layers (including the input 'layer')\"\"\"\n",
    "        ls = [w.shape[1] for w in self.W]\n",
    "        ls.append(self.W[-1].shape[0])\n",
    "        return ls\n",
    "\n",
    "    def predict(self, X, save=False):\n",
    "        A = X\n",
    "        if save:\n",
    "            # create empty lists for intemediary results\n",
    "            self.A = self.numberOfLayers * [0]\n",
    "            self.Z = self.numberOfLayers * [0]\n",
    "            # store input values\n",
    "            self.A[0] = A\n",
    "\n",
    "        # now calculate output of all layers (all in variable A) and return last one\n",
    "        for i in range(self.numberOfLayers - 1):\n",
    "            # calculate Z and A\n",
    "            #. Your solution here ...\n",
    "            if save:\n",
    "                # store intemediary results (for backprop)\n",
    "                self.Z[i] = Z\n",
    "                self.A[i+1] = A\n",
    "        return A\n",
    "\n",
    "    def backprop(self, Y):\n",
    "        L = self.numberOfLayers\n",
    "        m = len(Y)\n",
    "        self.D = L * [0]\n",
    "\n",
    "        # Compute loss of final layer and assign to self.D[L-1]\n",
    "        #. Your solution here ...\n",
    "\n",
    "        # iterate backwards through layers\n",
    "        for i in range(L-2,0,-1):\n",
    "            # Calculate the derivatives of the loss\n",
    "            # with respect to output of layers\n",
    "            # and assign tp self.D[i]\n",
    "            #. Your solution here ...\n",
    "\n",
    "    def grad_descent(self, alpha):\n",
    "        L = len(self.layerSizes)\n",
    "        for i in range(0,L-1):\n",
    "            # Update the values of self.b[i] and self.W[i]\n",
    "            #. Your solution here ...\n",
    "\n",
    "    def fit(self, X, Y, niter, alpha, verbose=False, testset=None):\n",
    "        if verbose:\n",
    "            cost_learn = np.zeros((niter))\n",
    "            cost_test = np.zeros((niter))\n",
    "        else:\n",
    "            cost_learn = None\n",
    "            cost_test = None\n",
    "\n",
    "        for i in range(niter):\n",
    "            A = self.predict(X, save=True)\n",
    "            self.backprop(Y)\n",
    "            self.grad_descent(alpha)\n",
    "            if verbose:\n",
    "                cost_learn[i] = 1 / 2 / len(Y) * np.sum((A-Y)**2)\n",
    "                A_test = self.predict(testset[0], save=False)\n",
    "                cost_test[i] = 1 / 2/ len(testset[1]) * np.sum((A_test-testset[1])**2)\n",
    "                if i % (niter//10) == 0:\n",
    "                    print(f\"iteration {i}, cost on learning set = {cost_learn[i]:10.4f}, cost on test set {cost_test[i]:10.4f}\")\n",
    "\n",
    "        return cost_learn, cost_test\n",
    "\n",
    "    def loadNetwork(self, file):\n",
    "        (self.W, self.b) = pickle.load(open(file, 'rb'))\n",
    "        self.layerSizes = self.getLayerSizes()\n",
    "\n",
    "    def saveNetwork(self, file):\n",
    "        pickle.dump((self.W, self.b), open(file, 'wb+'))\n",
    "\n",
    "    def __str__(self):\n",
    "        s = \"\"\n",
    "        s += \"Neural Network\\n\"\n",
    "        s += \"=\" * 70 + \"\\n\"\n",
    "        s += \"nodes in layers: \" + str(self.layerSizes) + \"\\n\"\n",
    "        l = 1\n",
    "        for W,b in zip(self.W, self.b):\n",
    "            s += \"Layer \" + str(l) + \" to \" + str(l+1) + \"\\n\"\n",
    "            s += \"\\t W = \" + str(W) + \"\\n\"\n",
    "            s += \"\\t b = \" + str(b) + \"\\n\"\n",
    "            l += 1\n",
    "        s += \"=\" * 70 + \"\\n\"\n",
    "        return s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EXAkpn3Cam6M"
   },
   "source": [
    "### Step 1: prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-4x9vJWham6N"
   },
   "source": [
    "Finish the implementation of the `predict` method. You can use the code below to test if it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1701602613065,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "wxk-V4aQam6N",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-6e4734f74c231a87",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "b08d077f-3b24-432d-a0c5-1360790685e3"
   },
   "outputs": [],
   "source": [
    "# manually create network\n",
    "nn1 = NN(layerSizes=(2,2,1))\n",
    "\n",
    "W1 = np.array([[20.0, 20.0], [-20.0, -20.0]])\n",
    "W2 = np.array([[20.0, 20.0]])\n",
    "b1 = np.array([-10,30])\n",
    "b2 = np.array([-30])\n",
    "\n",
    "nn1.W = [W1, W2]\n",
    "nn1.b = [b1, b2]\n",
    "\n",
    "# create test data\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]]).astype(float)\n",
    "\n",
    "# predict output\n",
    "Y_output = nn1.predict(X)\n",
    "print(Y_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cdewOs26am6O"
   },
   "source": [
    "### Step 2: backprop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "m3ipJlRGam6O"
   },
   "source": [
    "Finish the implementation of the method `backprop`. You can use the code below to test if it works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 246,
     "status": "ok",
     "timestamp": 1701602639021,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "7RFKdUwbam6P",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-77542dda2215ae4c",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "outputId": "ed91c704-b5b5-4601-c441-e0c14d9ff941"
   },
   "outputs": [],
   "source": [
    "# create network (with fixed seed ---needed for automatic grading---)\n",
    "nn2 = NN(layerSizes=(2,2,1), seed=42)\n",
    "\n",
    "print(nn2)\n",
    "\n",
    "# create test data\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]]).astype(float)\n",
    "Y = np.array([[0], [1], [1], [0]])\n",
    "\n",
    "# save the results of the forward propagation\n",
    "nn2.predict(X, save = True)\n",
    "\n",
    "# run back propagation to compute the derivatives\n",
    "# of the (intermediary) activations\n",
    "nn2.backprop(Y)\n",
    "\n",
    "D_layer2 = nn2.D[1]  # these values will be tested\n",
    "D_layer3 = nn2.D[2]  # these values will be tested\n",
    "\n",
    "# print the losses\n",
    "print(D_layer2)\n",
    "print(D_layer3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LaVpCfaam6Q"
   },
   "source": [
    "### Step 3: descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vWm-0sYsam6Q"
   },
   "source": [
    "Finish the implementation of the method `grad_descent`. You can use the code below to test if it works correctly. There is no correct answer defined anymore. It's up to you to decide if it works well enough."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1432,
     "status": "ok",
     "timestamp": 1701602663053,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "ENQTQKrWam6Q",
    "outputId": "ec372271-cad5-4ff0-93e1-f7b3bb08de7d"
   },
   "outputs": [],
   "source": [
    "# create data\n",
    "X = np.array([[0,0], [0,1], [1,0], [1,1]]).astype(float)\n",
    "Y = np.array([[0], [1], [1], [0]]).astype(float)\n",
    "\n",
    "# define network\n",
    "np.random.seed(73478)\n",
    "nn3 = NN(layerSizes=(2,2,1), activation_functions=(sigm, sigm_prime))\n",
    "\n",
    "# show initial state\n",
    "print(\"Network before learning:\")\n",
    "print(nn3)\n",
    "print(\"Prediction before learning\")\n",
    "print((1000 * nn3.predict(X)).astype(int))\n",
    "print()\n",
    "\n",
    "# train network\n",
    "nn3.fit(X,Y,10000, 10)\n",
    "\n",
    "# results\n",
    "print(\"Netwok after learning:\")\n",
    "print(nn3)\n",
    "print(\"Prediction after learning\")\n",
    "print((1000 * nn3.predict(X)).astype(int))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WA_M73Ugam6R"
   },
   "source": [
    "## Testing on Noisy XOR Problem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FmpNiyrAam6R"
   },
   "source": [
    "First we generate the noisy 'XOR' data, run the neural net classifier on this problem, and then visualize the results. In the cell below you only need to check if your implementation works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 565,
     "status": "ok",
     "timestamp": 1701602676943,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "E1iqHEaham6S",
    "outputId": "380d093b-0563-486f-e784-124985a34241"
   },
   "outputs": [],
   "source": [
    "m = 100\n",
    "X0 = 1.7 * np.random.randn(m//2, 2) + (9, 9)\n",
    "y0 = np.zeros((m//2))\n",
    "X1 = 1.7 * np.random.randn(m//2, 2) + (1, 1)\n",
    "y1 = np.zeros((m//2))\n",
    "X = np.vstack((X0, X1))\n",
    "y = np.hstack((y0, y1))\n",
    "X0 = 1.5 * np.random.randn(m//2, 2) + (1, 9)\n",
    "y0 = np.ones((m//2))\n",
    "X1 = 1.5 * np.random.randn(m//2, 2) + (9, 1)\n",
    "y1 = np.ones((m//2))\n",
    "X = np.vstack((X,X0,X1))\n",
    "y = np.hstack((y,y0,y1))\n",
    "plt.scatter(X[:,0], X[:,1], c=y, edgecolors='k', cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1701602680757,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "55yF-EiFam6S"
   },
   "outputs": [],
   "source": [
    "Y = y[:,np.newaxis] # reshape into (m,1) for neural network learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3234,
     "status": "ok",
     "timestamp": 1701602686797,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "_E5-DsVJam6T",
    "outputId": "3c45da30-9883-48b8-dd07-3245d9b4c32d"
   },
   "outputs": [],
   "source": [
    "nnXORnoisy = NN(layerSizes=(2,8,1))\n",
    "nnXORnoisy.fit(X, Y, 10000, 10)\n",
    "print(nnXORnoisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 701,
     "status": "ok",
     "timestamp": 1701602700049,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "CWP_xcODam6U",
    "outputId": "e18e23e5-75d3-4682-bf90-e41401fa7f38"
   },
   "outputs": [],
   "source": [
    "xmin = X[:,0].min() - 0.5\n",
    "xmax = X[:,0].max() + 0.5\n",
    "ymin = X[:,1].min() - 0.5\n",
    "ymax = X[:,1].max() + 0.5\n",
    "mx, my = np.meshgrid(np.arange(xmin, xmax, 0.1),\n",
    "                  np.arange(ymin, ymax, 0.1))\n",
    "Z = nnXORnoisy.predict(np.c_[mx.ravel(), my.ravel()])\n",
    "Z = 1*(Z>0.5)\n",
    "Z = Z.reshape(mx.shape)\n",
    "plt.pcolormesh(mx, my, Z, cmap=plt.cm.Paired, shading='auto');\n",
    "plt.scatter(X[:,0], X[:,1], c=y, edgecolors='k', cmap=plt.cm.Paired);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all went well, you should see that the classification only went wrong for one point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The MNIST Data Set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The MNIST data set consists of small images of handwritten digits and is considered the \"hello world!\" for classification programs in machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_mnist = load_digits()\n",
    "print(dataset_mnist.DESCR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hxIZtd5cbUR5"
   },
   "source": [
    "It is important to normalize the dataset before using it for learning and testing. For the learning set, we do the normalization by subtracting the mean of a feature and divide by the standard deviation of that feature (like the z-score). **Note that we have to use the mean and standard deviation of the learning set to normalize the test set as well!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 229,
     "status": "ok",
     "timestamp": 1701602829137,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "0GjBBp9LbUR6",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-1ffed17399716900",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "X_mnist = dataset_mnist.data.astype(float)\n",
    "y_mnist = dataset_mnist.target\n",
    "m_mnist = len(y_mnist)\n",
    "m_mnist_learn = 2 * m_mnist // 3\n",
    "m_mnist_test = m_mnist - m_mnist_learn\n",
    "\n",
    "# First we divide the data into learning and test set\n",
    "idx = np.arange(m_mnist)\n",
    "rng = np.random.default_rng(seed=487)  # needed to have everybode work with the same learning and test set\n",
    "rng.shuffle(idx)\n",
    "X_mnist_learn = X_mnist[idx[:m_mnist_learn]]\n",
    "y_mnist_learn = y_mnist[idx[:m_mnist_learn]]\n",
    "X_mnist_test = X_mnist[idx[m_mnist_learn:]]\n",
    "y_mnist_test = y_mnist[idx[m_mnist_learn:]]\n",
    "\n",
    "# Normalize both the learning set and the test set\n",
    "# do the normalization 'in place'\n",
    "#. Your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SAoxCAsVbUR8"
   },
   "source": [
    "The target vector has values from 0 to 9 indicating the digits. We could use this as the target value for the neural network as well, but then we are using a neural network as a regression system. For classification, it is far better to have as many nodes in the final layer as there are classes (10). The first value in the last layer then indicates whether the example presented at the input belongs to class '0', etc. A value of 1 then indicates certainty that is indeed a '0'. A value of 0 indicates it certainly is not a '0'. In a sense, the output of node i (numbering starting at 0) then is proportional to $P(Y=i|\\bf{X}=\\bf{x})$, the a posteriori probability that the image characterized by data vector $\\bf x$ belongs to class $i$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "o7cO2bj0bUR9"
   },
   "source": [
    "The target vector $\\bf y$ is therefore changed into target matrix $Y$, where each example in the dataset has a target values a vector of 10 elements with all zeros except for the $i$-th element if that example belongs to class $i$. A simple example:\n",
    "$$\\bf y = \\begin{bmatrix}0\\\\3\\\\5\\\\2\\\\7\\end{bmatrix}$$\n",
    "leads to\n",
    "$$Y = \\begin{bmatrix}\n",
    "1& 0& 0& 0& 0& 0& 0& 0& 0& 0\\\\\n",
    "0&0&0&1&0&0&0&0&0&0\\\\\n",
    "0&0&0&0&0&1&0&0&0&0\\\\\n",
    "0&0&1&0&0&0&0&0&0&0\\\\\n",
    "0&0&0&0&0&0&0&1&0&0\\end{bmatrix}$$\n",
    "Such encoding of a target vector is called **one-hot encoding.** In the function complete the `one_hot_encoding` function. (Note this can be done without writing a loop in Python)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 247,
     "status": "ok",
     "timestamp": 1701602834965,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "MHemr8iybUR9",
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-c1cd6f868080bb39",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def one_hot_encoding(y):\n",
    "    #. Your solution here ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1701602838296,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "mYGgQ-cobUR_"
   },
   "outputs": [],
   "source": [
    "Y_mnist_learn = one_hot_encoding(y_mnist_learn)\n",
    "Y_mnist_test = one_hot_encoding(y_mnist_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 545
    },
    "executionInfo": {
     "elapsed": 372,
     "status": "ok",
     "timestamp": 1701602839575,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "aDqXUJ6TbUSA",
    "outputId": "c5ee1f37-0a79-4886-93ae-ac21c6550b52"
   },
   "outputs": [],
   "source": [
    "i=500 # pick any number in the data set\n",
    "plt.imshow(dataset_mnist.images[i], interpolation='nearest'); plt.gray();\n",
    "plt.text(0,7,str(dataset_mnist.target[i]),bbox=dict(facecolor='yellow', alpha=0.9)); plt.axis('off');\n",
    "print(dataset_mnist.images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z_V3KYf8bUSA"
   },
   "source": [
    "To show a somewhat nicer image, change the interpolation flag from 'nearest' into 'gaussian'. Interpolation (aka estimating values in between the pixels) is a subject in the course on image processing and computer vision (ICV)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 643
    },
    "executionInfo": {
     "elapsed": 16950,
     "status": "ok",
     "timestamp": 1701602860316,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "koEjcsU3bUSB",
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-06203526df89d5b8",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "outputId": "fa7d5aa8-391c-4ccf-b168-b514b147558b"
   },
   "outputs": [],
   "source": [
    "print(X_mnist_learn.shape)\n",
    "print(Y_mnist_learn.shape)\n",
    "nn = NN(layerSizes=(64, 10), seed=77) # this is (almost) just 10 logistic regression units in parallel\n",
    "cost_mnist_learn, cost_mnist_test = nn.fit(X_mnist_learn, Y_mnist_learn,\n",
    "                                           5000, 10, verbose=True,\n",
    "                                           testset=(X_mnist_test, Y_mnist_test))\n",
    "plt.plot(cost_mnist_learn, label='learning cost')\n",
    "plt.plot(cost_mnist_test, label='test cost')\n",
    "plt.ylim(0,1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 435
    },
    "executionInfo": {
     "elapsed": 373,
     "status": "ok",
     "timestamp": 1701602860654,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "lk7rD2N9bUSC",
    "outputId": "8291d717-73a3-409e-9f78-411dd57c674f"
   },
   "outputs": [],
   "source": [
    "plt.plot(cost_mnist_learn, label='learning cost')\n",
    "plt.plot(cost_mnist_test, label='test cost')\n",
    "plt.ylim(0, 0.1)\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 206,
     "status": "ok",
     "timestamp": 1701602886624,
     "user": {
      "displayName": "Rein van den Boomgaard",
      "userId": "14643741240655522923"
     },
     "user_tz": -60
    },
    "id": "HGeKNxO_bUSC",
    "outputId": "1090d205-737a-4521-cc5c-78b552cb7677"
   },
   "outputs": [],
   "source": [
    "yp = np.argmax(nn.predict(X_mnist_test), axis=1)\n",
    "accuracy = np.sum(yp==y_mnist_test).astype(int)/len(yp)*100\n",
    "print(f\"accuracy = {accuracy:5.2f}\")"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
