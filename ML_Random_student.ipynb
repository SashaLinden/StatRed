{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Flipping-a-coin\" data-toc-modified-id=\"Flipping-a-coin-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Flipping a coin</a></span></li><li><span><a href=\"#Histograms-and-Probability-Density-Functions\" data-toc-modified-id=\"Histograms-and-Probability-Density-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Histograms and Probability Density Functions</a></span></li><li><span><a href=\"#Mean-of-Random-Variables\" data-toc-modified-id=\"Mean-of-Random-Variables-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Mean of Random Variables</a></span></li><li><span><a href=\"#The-Normal-Distribution\" data-toc-modified-id=\"The-Normal-Distribution-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>The Normal Distribution</a></span></li><li><span><a href=\"#Central-Limit-Theorem\" data-toc-modified-id=\"Central-Limit-Theorem-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Central Limit Theorem</a></span></li><li><span><a href=\"#Monte-Carlo-Experiments\" data-toc-modified-id=\"Monte-Carlo-Experiments-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Monte Carlo Experiments</a></span><ul class=\"toc-item\"><li><span><a href=\"#Calculating-$\\pi$\" data-toc-modified-id=\"Calculating-$\\pi$-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Calculating $\\pi$</a></span></li><li><span><a href=\"#Calculating-Probability\" data-toc-modified-id=\"Calculating-Probability-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Calculating Probability</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# INF-SR: Random Variables (Programming)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Flipping a coin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We flip a coin where $ùñØ(\\text{\"tails\"})=p$ and $p$ is not necessarily equal to $0.5$ (i.e. not necessarily a fair coin). We repeat the experiment of flipping the coin $n$ times and let $X$ be the random variable that counts how many times $k$ we find ‚Äútails‚Äù up. The p.m.f. $p_X(k)$ gives the probability that we find $k$-times 'heads' up in a series of $n$ coint tosses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula for $p_X(k)$ can be found in the lecture notes. In the cell below implement the `p_X` function. **You cannot use the `scipy.stats.binom` function** or any other function that implements this for you. Only the factorial function from scipy can be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "binomial_prob_code",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from scipy.special import factorial\n",
    "\n",
    "def p_X(k, n, p):\n",
    "    return factorial(n) / (factorial(k) * factorial(n - k)) * p**k * (1 - p)**(n - k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the cell below write the code to plot the DISCRETE probability mass function $p_X(k)$ for $n=20$ and $p\\in\\{0.25, 0.50, 0.75\\}$. Create the plot, including a `plt.show()` call, in the function `plot_binom_discrete(n, p)`. This function should also return the x-axis values `ks` and y-axis values `ps` used for the plot. \n",
    "\n",
    "Make sure `ks` contains precisely the values for which the probability is positive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "plot_binomial",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_binom_discrete(n, p):\n",
    "    ks = np.arange(n + 1)\n",
    "    ps = [p_X(k, n, p) for k in ks]\n",
    "    plt.stem(ks, ps, label=f'p={p}')\n",
    "    plt.legend()\n",
    "    plt.xlabel('k')\n",
    "    plt.ylabel('P(X=k)')\n",
    "    plt.show()\n",
    "\n",
    "    return ks, ps\n",
    "\n",
    "# Call the function here to plot.\n",
    "n = 20\n",
    "for p in [0.25,0.5,0.75]:\n",
    "    ks, ps = plot_binom_discrete(n, p)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next cell perform some numerical tests to 'prove' the equality (for different combinations of $n$ and $p$)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "illustration_binomial",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Perform some numerical tests to 'prove' the equality (for different combinations of $n$ and $p$).\n",
    "\n",
    "n = 2\n",
    "p = 0.5\n",
    "k = 1\n",
    "print(f'p_X({k}, {n}, {p}) = {p_X(k, n, p)}')\n",
    "\n",
    "n = 4\n",
    "p = 0.5\n",
    "k = 1\n",
    "print(f'p_X({k}, {n}, {p}) = {p_X(k, n, p)}')\n",
    "\n",
    "n = 10\n",
    "p = 0.75\n",
    "k = 7.5\n",
    "print(f'p_X({k}, {n}, {p}) = {p_X(k, n, p)}')\n",
    "\n",
    "n = 20\n",
    "p = 0.25\n",
    "k = 5\n",
    "print(f'p_X({k}, {n}, {p}) = {p_X(k, n, p)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Histograms and Probability Density Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given a sample of $m$ values from a continuous random variable $X$ it is easy to draw the histogram of these values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.normal(size=10000)\n",
    "h, be = np.histogram(sample, bins=50)\n",
    "plt.bar(be[:-1], h, width=be[1]-be[0], align='edge');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The more values in your sample, the better the shape of the histogram resembles the probability distribution of the standard normal distribution. But it resembles **only the shape** not the numerical values. When we plot the pdf we get:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fStdNormal(x):\n",
    "    return 1/np.sqrt(2*np.pi) * np.exp( -x**2 / 2 )\n",
    "x = np.linspace(-5, 5, 1000)\n",
    "plt.plot(x, fStdNormal(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the scale on the vertical axis is totally different. It is your task to normalize a histogram of a distribution (not necessarily the normal distribution) such that its values do approximate the pdf of the distribution. More formally, let $f_X$ be the pdf of the RV $X$. Let ``h`` be the N bins histogram array of shape ``(N,)`` and let ``be`` be the bin edges array. The array of midpoints ``xx`` of the bins is made with ``xx = be[:-1]+0.5*diff(be)``. The goal is now to normalize ``h`` into array ``pdf`` such that ``pdf[i]`` approximates $f_X(x[i])$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "normalize_histogram",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def histogram2pdf(h, be):\n",
    "    pdf = h / np.sum(h) / (be[1] - be[0])\n",
    "    return pdf\n",
    "\n",
    "sample = np.random.normal(size=10000)\n",
    "h, be = np.histogram(sample, bins=30)\n",
    "\n",
    "xx = np.linspace(be[0],be[-1],1000)\n",
    "plt.bar(be[:-1], histogram2pdf(h, be), width=be[1]-be[0], color='lightgray', align='edge');\n",
    "plt.plot(xx, fStdNormal(xx), 'g');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean of Random Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the random variable $X\\sim \\text{Uniform}(-1,1)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python you can draw 10000 samples from this distribution with the function `np.random.uniform(low=-1,high=1,size=10000)`. Doing this and making a normalized histogram leads to:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = np.random.uniform(low=-1, high=+1, size=10000)\n",
    "h, be = np.histogram(sample, bins=50)\n",
    "\n",
    "# Now normalize the histogram before plotting it.\n",
    "plt.bar(be[:-1], histogram2pdf(h, be), width=be[1]-be[0], align='edge');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we define the random variable $M_2=(X_1+X_2)/2$. Plot a histogram (with 50 bins) of the 10000 $M_2$ values. Normalize the histogram to approximate the pdf of $M_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "histogramplot_M_2",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "np.random.seed(98394829)\n",
    "sampleXi = np.random.uniform(low=-1, high=+1, size=(10000,2))\n",
    "sampleMi = np.mean(sampleXi, axis=1)\n",
    "\n",
    "h, be = np.histogram(sampleMi, bins=50)\n",
    "plt.bar(be[:-1], histogram2pdf(h, be), width=be[1]-be[0], align='edge');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now redo the plots for $M_n$ with $n=1, 2, 3, 5, 10, 100$. Write your solution in the `plot_M_n(n)` function, which should construct the plot and call `plt.show()`. Then it should return the x-axis values `xs` and y-axis values `ps` used in the plot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "histogram_M_i",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def plot_M_n(n):\n",
    "    np.random.seed(98394829)\n",
    "    \n",
    "    sampleXi = np.random.uniform(low=-1, high=+1, size=(10000,n)) \n",
    "    sampleMi = np.mean(sampleXi, axis=1)\n",
    "\n",
    "    ps = []\n",
    "    xs = []\n",
    "    h, be = np.histogram(sampleMi, bins=50)\n",
    "    ps = histogram2pdf(h, be)\n",
    "    xs = be[:-1]\n",
    "    plt.bar(be[:-1], histogram2pdf(h, be), width=be[1]-be[0], align='edge')\n",
    "    plt.show()\n",
    "\n",
    "    return xs, ps\n",
    "\n",
    "# Call the function here for the different values of n.\n",
    "for n in [1,2,3,5,10,100]:\n",
    "    xs,ps = plot_M_n(n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can you make an hyphothesis for the pdf of $M_{2}$? I.e. can you 'guess' the formula for this pdf? And what about $M_{100}$? We will come back to this question in a subsequent exercise. (these questions won't be graded...)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Normal Distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You have already written the code for the pdf of the standard normal distribution. Make sure the function ``fStdNormal`` is working correctly at this point."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now define the function ``fNormal`` for a normal distribution with mean $\\mu$ and standard deviation $\\sigma$. You have to use your ``fStdNormal`` function. Refer to the  section in the lecture notes on [Scaled and Shifted Distributions](https://staff.fnwi.uva.nl/r.vandenboomgaard/MachineLearning/LectureNotes/ProbabilityStatistics/rvCalculations.html#scaled-and-shifted-distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "code_fNormal",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fNormal(x, mu, sigma):\n",
    "    #. Your solution here ...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "test_fNormal",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "x = np.linspace(-5, 15, 1000)\n",
    "f = fNormal(x, 5, 3)\n",
    "plt.plot(x, f);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The cumulative distribution function for the standard normal distribution can not be written down in an analytical expression. We have to use the `scipy.special.erf` function (which numerically approximates the cumulative distribution function). Without proof we state that $F_X(x)$ can be defined as:\n",
    "$$F_X(x) = \\tfrac{1}{2} \\left(1 + \\text{erf}\\left(\\frac{x}{\\sqrt{2}}\\right)\\right)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy\n",
    "def FStdNormal(x):\n",
    "    return 0.5 * (1 + scipy.special.erf(x/np.sqrt(2)))\n",
    "\n",
    "x = np.linspace(-4,4,1000);\n",
    "plt.plot(x, FStdNormal(x));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the ``FStdNormal`` function to write the function ``FNormal(x, mu, sigma)`` for the cumulative distribution of a normal distribution with expectation $\\mu$ and variance $\\sigma^2$. Again we refer you to the  section in the lecture notes on [Scaled and Shifted Distributions](https://staff.fnwi.uva.nl/r.vandenboomgaard/MachineLearning/LectureNotes/ProbabilityStatistics/rvCalculations.html#scaled-and-shifted-distributions)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "code_FNormal",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def FNormal(x, mu, sigma):\n",
    "    #. Your solution here ...\n",
    "    \n",
    "x = np.linspace(-5, 20, 1000)\n",
    "plt.plot(x, FNormal(x, 10, 3));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can draw a sample from the normal distribution using the function `numpy.random.normal(loc=mu, scale=sigma, size=None)`. Use this function to draw 10000 numbers from a normal distribution with $\\mu=3$ and $\\sigma=2$. Make and draw a histogram for all these numbers and scale it to be an approximation of the pdf. Also plot the pdf on top of the histogram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "pdf_on_histogram",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "sample = np.random.normal(loc=3, scale=2, size=10000)\n",
    "\n",
    "#. Your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Central Limit Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In a previous exercise in this notebook you have calculated the mean of $n$ observations from a uniform distribution. The RV corresponding with this random experiment was called $M_n$. In that previous exercise you have plotted the histogram of a sample of $M_n$ (for several values of $n$)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that\n",
    "$$M_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$$\n",
    "where the $X_i\\sim\\text{Uniform}(-1,1)$ are iid.\n",
    "In a homework ANS exercise you had to prove that $E(M_n) = E(X)$ and that $\\text{Var}(M_n) = \\text{Var}(X)/n$. In that same exercise you have calculated the expectation and variance of a uniform distribution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With all this knowledge you can calculate and plot the pdf of a normal distribution with $\\mu=E(M_n)$ and $\\sigma^2 = \\text{Var}(M_n)$. So below in `plot_M_n_with_pdf(n)`, make the plots again of the histograms of the $M_n$ samples for all values of $n$ (this is a simple copy and paste). Then overlay the bar plot for each $n$ with the normal distribution pdf. \n",
    "\n",
    "Let the function return `xs_hist`, `ps_hist`, `xs_pdf` and `ps_pdf`, where the first two are the x and y values used to plot the histograms, and the last two are the x and y values used to plot the pdf.\n",
    "Use a `np.linspace` with logical start/stop values and `num=1000` to define `xs_pdf`. Don't forget to align the bar plot for the histogram to `align='edge'`.\n",
    "\n",
    "If all is well you will observe that for $n=1$ the normal pdf is nowhere near the uniform pdf but that for $n$ getting increasingly larger the histogram of the sample of $M_n$ is getting closer and closer to the normal pdf (with appropriate mean and standard deviation of course). This illustrates what is called **the central limit theorem**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "histogram_M_10_normal_pdf",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def plot_M_n_with_pdf(n):\n",
    "    np.random.seed(98394829)\n",
    "    \n",
    "    #. Your solution here ...\n",
    "\n",
    "    return xs_hist, ps_hist, xs_pdf, xs_hist\n",
    "\n",
    "# Call the function here for the different values of n.\n",
    "#. Your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Monte Carlo Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='red'>\n",
    "    This entire section until the end of the notebook does not count towards the final grade of this labexercise. There is some autograding done but only for your information.\n",
    "    </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To quote Wikipedia: \"Monte Carlo experiments, are a broad class of computational algorithms that rely on repeated random sampling to obtain numerical results. The underlying concept is to use randomness to solve problems that might be deterministic in principle.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating $\\pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to calculate a numerical value of $\\pi$. Perhaps the most inaccurate way to do so is the following random experiment. Consider the two RV's $X$ and $Y$ that iid: $X, Y \\sim \\text{Uniform}(-1, +1)$. Every drawing gives a point $(X,Y)$ within the square. Every position in the square is equally probable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating the proportion of points that fall in the disk with radius 1 centered at the origin and the total number of points within the square  will give an approximation of $\\pi$. Extend the following code in such a way that the sample set is separated into a set of points within the unit circle and a set of points outside the unit circle. Plot the two different point sets in different colors and give the figure a title with ``plt.title(r'$\\pi\\approx %5.4f$' % hat_pi);`` where ``hat_pi`` is the estimation of $\\pi$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "MC_pi",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def monte_carlo_pi(samples):\n",
    "    sampleX12 = np.random.uniform(low=-1, high=+1, size=(samples, 2))\n",
    "    X = sampleX12[:,0]\n",
    "    Y = sampleX12[:,1]\n",
    "    plt.scatter(X, Y, marker='.')\n",
    "    plt.axis('equal')\n",
    "    \n",
    "    #. Your solution here ...\n",
    "\n",
    "    return hat_pi\n",
    "\n",
    "monte_carlo_pi(2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating Probability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let rv $X$ be distributed with pdf $f_X$. We are given a function to get a sample of this distribution. Write the code to calculate (estimate) the probability $a\\leq X \\leq b$ with a Monte Carlo experiment. Calculate the probabilities $p_1=P(-1\\leq X \\leq 1)$, $p_2=P(-2\\leq X \\leq 2)$ and $p_3=P(-3\\leq X \\leq 3)$ in case $X\\sim\\text{Normal}(0,1)$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "MC_normal_prob",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_probability(sample, a, b):\n",
    "    #. Your solution here ...\n",
    "\n",
    "np.random.seed(1)\n",
    "sample = np.random.normal(size=100000)\n",
    "\n",
    "# Calculate the probabilities p1 = P(-1 <= X <= 1), p2 = P(-2 <= X <= 2) and p3 = P(-3 <= X <= 3)\n",
    "#. Your solution here ...\n",
    "\n",
    "print(p1, p2, p3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now consider two iid standard normally distributed random variables $X$ and $Y$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(1)\n",
    "sampleX = np.random.normal(size=1000)\n",
    "sampleY = np.random.normal(size=1000)\n",
    "plt.scatter(sampleX, sampleY, marker='.')\n",
    "plt.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What is the probability $P((-1\\leq X \\leq 1) \\cap (-1\\leq Y \\leq 1))$? First give a mathematical calculation in the next cell:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-149a674d15baa800",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "#. Your solution here ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And in the next cell a computational 'proof':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "experiment_0p46",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_2d_p(sampleX, sampleY):\n",
    "    # Estimate $P((-1\\leq X \\leq 1) \\cap (-1\\leq Y \\leq 1))$.\n",
    "    #. Your solution here ...\n",
    "\n",
    "from IPython.display import display, Math\n",
    "\n",
    "p = estimate_2d_p(sampleX, sampleY)\n",
    "display(Math(r'$$P((-1\\leq X \\leq 1) \\cap (-1\\leq Y \\leq 1)) = %5.2f$$' % p))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that increasing the dimension of feature space will decrease the probability of finding a value in a 1 standard deviation box around the mean. And it decreases quite rapidly! This is one of the ways the **curse of dimensionality shows up**."
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": true,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
